\chapter{Taxonomy-Based Glyph Design}
\label{chap:glyph-tax}

\begin{chapquote}{Kenneth Boulding}{``In science, any model depends on a pre-chosen taxonomy, a set of classifications into which we divide the enormous complexity of the real world...''}
\end{chapquote}

\section{Introduction}
A good glyph design can enable better, more efficient visual search during interactive visualization, and facilitate effective learning and memorisation using the visual encoding scheme.
A less effective visual design may suffer from various shortcomings such as being perceptually confusing, semantically ambiguous, difficult to learn and remember, or unable to accommodate low-resolution display devices.
Most accepted designs have undergone an enduring process of evolution, refinement, and standardisation.
One could not and should not remove the necessity for such processes in glyph design.
Meanwhile, the design process for a glyph set usually relies on an assortment of creativity, artistic skill, domain knowledge, intuition about users, and sometimes personal preference.
While most of these qualities are absolutely helpful and some are inevitable, it is highly desirable to introduce ``systematicism'' and objectivity into the design process.

To demonstrate our approach, we elected the field of experimental biology as a test bed for developing a systematic methodology to create a glyph-based visual mapping for visualising experimental design and experimental processes.
While experimental design is at the heart of biological data evidence gathering, representation of such information is confined to either verbose description or ineffective representations.
This claim is backed by a survey of public biodata repositories, devised to ensure data perennity, scientific scrutiny, and reproducibility.
As illustrated in Figure \ref{fig:teaser}(a), workflows are traditionally drawn as text-based diagrams.
Text labels are indices of concepts, and usually they do not encode multivariate information directly.
As stated by Ware \cite{ware13}, text-labelled boxes are costly in terms of display space usage as well as time required for visual search since parsing and interpretation of text is a slow post-attentive process.
They are particularly ineffective when one needs to compare between different workflows or to identify unusual or missing components in a workflow.

\begin{figure*}[ht!]
\centering
 \includegraphics[width=.95\textwidth]{images/glyph-taxonomy/bio-workflow-isacreator.eps}
\caption{A) Workflow as rendered currently using toolkits such as \emph{GraphViz}.
B) We propose to replace the textual labels with glyphs, while allowing interactive access to detailed descriptions. This makes it easy to gain an overview, search components, and compare workflows. The screenshot shows a prototype developed within ISAcreator, a system for capturing biological experiment metadata.}
\label{fig:teaser}
\vspace{-5mm}
\end{figure*}


Therefore, exploring an alternative in the form of glyph-based representations, which are at the core of many successful schematic diagrams in the history of sciences, engineering, and business management, offers a potentially more effective means for depicting these workflows.  
This presents us with an interesting case study where other types of design approaches would not be appropriate, especially in dealing with several hundreds of conceptual names.

It is important to note that domain experts are in general more willing and able to learn and memorise an encoding scheme in order to improve the accuracy and efficiency of routine tasks. At the same time, it is also necessary for an encoding scheme to facilitate effective learning and remembering through appropriate abstraction and metaphors.

Motivated by this case study, we made an observation that when a large number of concepts (or taxa) are organised into a taxonomic tree, the hierarchy typically represents an ordering of different categorisation schemes.
The schemes that are higher-up in the taxonomy (closer to the root) are usually considered to be more important, which reflect their conceptual coverage, frequency of usage, domain-specific convention, and some other measurable factors.
In terms of visual encoding, higher up schemes should ideally be mapped to visual channels that have more discriminative capacity.
Hence, we can explore the parallel between the taxonomic hierarchy and the ordering of visual channels based on discriminative capacity to formulate a systematic and relatively objective process for designing a glyph set.
This approach addresses one of the most common criticisms of data glyphs: the data to visual attribute mapping bias stated by Matt Ward \cite{ward08}.

Given a large data repository that encompasses many concepts, our design process is composed of four major steps:
\begin{enumerate}
\item gathering and processing raw metadata for obtaining a set of taxa (names);
\item formulating a taxonomy based on a set of categorisation schemes (Section \ref{sec:Taxonomy});
\item carrying out visual design, which includes the sub-process of determining the ordering of visual channels, proposing optional visual mappings, and identifying metaphoric abstractions and associations (Section \ref{sec:Glyphs}); and
\item implementing a glyph-based visualization system, in our case, for depicting workflows of biological experiments (Section \ref{sec:Workflow}).
\end{enumerate}

Similar to most design processes, it is helpful to conduct all stages in a progressive and iterative manner.
As glyph-based visualization is normally deployed in a specific application domain, it is important to involve domain experts at every stage of the design process.
During this work, we met with domain experts on a weekly basis.

\section{Related Work}
\label{sec:RelatedWork}
In this section, we give a brief overview of two most relevant areas in visualization, \emph{glyph-based visualization} and \emph{workflow visualization}.
The remainder background information includes the biological data management, perceptual guidance, and categorisation algorithms, which will be described in the following sections where the relevant technical details are discussed.

\subsection{Glyph-based Visualization}
%
There are many examples of glyph usage in the literature spanning many disciplines, especially in conjunction with schematic diagrams. Such examples are  documented in Chapter \ref{chap:related_work} Section \ref{sec:glyph-examples}. 

There have been some recent efforts to use glyph-based visualization in biological sciences.
One noticeable attempt is the \emph{Systems Biology Graphical Notation} (\emph{SBGN}) \cite{lenovere09}.
The design of \emph{SBGN} makes use of the notional representations of UML with some modifications to describe the biological entities and their interactions within a biological system.
\emph{GenoCAD} \cite{cai10} provides a grammar-based language for representing and searching DNA sequences and for building genetic constructs from DNA sequences, facilitating the use of conventional link diagrams.
Both systems rely heavily on text labels.
In handling a large collection of workflows, they exhibit a few shortcomings, such as inefficiency in using display space and ineffectiveness in supporting some visualization tasks, such as comparisons and novelty or anomalies detection in workflows.

In the literature, Ward \cite{ward08} and Karve \cite{Karve07} encouraged glyph designers to consider visual perception when constructing glyphs.
Others, including Hemenway \cite{hemenway82} and Lewis and Rosenholtz \cite{lewis04} examined the design space of icons, which normally encode less information than glyphs.
There were perceptual studies showing the merits of icons over text labels by Muter and Mayson \cite{muter86} and Pellegrino \etal \cite{pellegrino77}, as well as those showing the contrary by Wiedenbeck \cite{wiedenbeck99}.
Building on such discussions, this work aims to address a methodological need for a systematic approach to glyph design for applications where large collections of concepts need to be visually encoded using glyphs.

%%In \cite{ward08}, Ward summarises that there is a need for novel mechanisms to display the growing amounts of information becoming available via the data deluge. He details the need for multi-resolution strategies \cite{ward08} giving varying levels of detail proportional to a users focus on the overall visualization.%%

\subsection{Workflow Visualization}
%
The need for \emph{workflow visualization} is pervasive across many domains.
For example, in business and management the\emph{Gantt chart} is a form of text-based workflow visualization, while \emph{BPMN} (Business Process Model and Notation) and EPC (Event-driven Process Chain) make use of icons to enrich text labels.
In engineering disciplines, various schematic diagrams, such as UML (Unified Modelling Language), Petri-net and circuit diagrams, are used to convey data flow and process interaction.

In this work, we consider workflows used to describe biological experiments. 
This class of workflow visualization renders the processes enacted on biological materials in an experiment (e.g., removal of blood sample from patient).
There has been little effort to develop tools that address the domain-specific needs.
Scientists usually use generic text-based graph drawing tools such as GraphViz \cite{GraphViz::2012}.

One related aspect is \emph{pathway visualization}, which is concerned with the rendering of cellular biological processes.
An array of pathway visualization tools have been developed, some of which incorporate glyphs.
\emph{VANTED} \cite{junker06} overlays glyphs representing gene expression, enzyme, and metabolite profile data on top of pathway diagrams from \emph{KEGG} \cite{ogata99}.
\emph{GENeVis} \cite{bourqui09}, which also employs glyphs to represent multivariate data, is a comprehensive visualization toolkit for exploration of pathways in conjunction with temporal data.
\emph{GenoCAD} \cite{cai10}  has at its core a workflow generation system and relies on their glyph library for rendering the different biological processes within a cell.
\emph{SBGN-ED} \cite{czauderna10}, is an add-on for the \emph{VANTED} software and performs pathway creation using the aforementioned \emph{SBGN} \cite{lenovere09} visual language.
For example, \emph{Taverna} \cite{missier10} exploits colour-coded boxes combined with text to indicate process type.
\emph{KNIME} \cite{berthold08} uses glyphs to indicate process types in combination with more detailed text descriptions.


%%Pathline\cite{meyer10}, a tool to visualise gene expression alongside metabolite information within particular biological pathways; 

% ====================
\section{Motivation and Overview}
\label{sec:Motivation}
%
The advent of massively parallel techniques such as DNA microarray, mass-spectrometry based proteomics (and metabolomics), and next generation sequencing enables molecular biologists to collect, process, and manipulate biological signals on a new scale.
There have been serious efforts in biology to ensure quality of experimental records by providing data archiving infrastructures, and defining standards for adequate annotation with sufficient details for recapitulation of results.
A number of molecular biology signature databases have been or are being established to cover the main molecular dimensions: transcript, protein, and metabolites.
The captured metadata generally revolves around a similar configuration where sets of samples corresponding to different conditions are processed, measurements produced and analyses performed, delivering data that needs to be handled and interpreted.
While the availability of such metadata facilitates comparison across datasets and enables meta-analysis, providing the means to serve an overview of experimental design can assist analysts and data managers alike, from data selection according to relevancy, to error detection such as imbalances, irregularities or inconsistencies in records.

\textbf{Task Analysis.} In the context of meta-databases for experimental records, there are two main groups of users. The majority of users are those who create data for their biological experiments or retrieve data relevant to their scientific interests. Their tasks include:
\begin{enumerate}[label=(\alph*)]
\item entering and editing their own experimental records;
\item transforming workflow records to schematic diagrams for comparison, external memorisation, publication, and education;
\item uploading and downloading datasets;
\item querying and searching for relevant experiments;
\item understanding workflows of existing experimental designs;
\item identifying similarity and difference between workflows for a common task; and
\item understand pooling events and sample relations (derivation).
\end{enumerate}

The second group of users are curators who manage data archives. As biology or bioinformatics scientists themselves, they perform the above-mentioned tasks (d)-(g) frequently, and (b)-(c) occasionally. In addition, they also carry tasks for:
\begin{enumerate}[label=(\alph*)]
\setcounter{enumi}{7}
\item checking syntactic correctness of submitted workflows;
\item checking semantic correctness of submitted workflows which usually involves reading the associated publications then comparing the submitted workflows with those described in the publications;
\item interacting with authors of submitted workflows to clarify any inconsistency and misunderstanding;
\item making appropriate corrections in submitted records where necessary;
\item augmenting with appropriate annotation based on additional information found in the associated publications;
\item providing authors with submission feedback;
\item forming an up-to-date overview about the experiments in the data archives, and maintaining an insight about the provenance of the archives;
\item analysing the grouping, replication, distribution and trend of experiments;
\item analysing ambiguities, errors and uncertainty in experimental recording, and identifying the need to enrich and refine the relevant standards for ontology, labelling and annotation; and
\item providing tools to assist users in creating meta-data from raw data.
\end{enumerate}

It is not difficult to observe that effective workflow visualization can significantly improve users' capability in performing tasks (b), (e), (f), (g), (h), (i), (j), (l), (n), (o), and (p).

While it is necessary to evolve a glyph-based design for workflow visualization over a period, it is also important not to make the first step in an ad hoc manner. Such a process does not scale well with the requirements of the application concerned where a large number of concepts are to be encoded using glyphs. Therefore we adopt a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorisation and the ordering of discriminative capacity of visual channels.
Figure \ref{fig:workflow} depicts this process.

\begin{figure}[t!]
\centering
\includegraphics[width=\textwidth]{images/glyph-taxonomy/workflow.eps}
\caption{A systematic process for creating glyph-based representations.}
\label{fig:workflow}
\vspace{-10pt}
\end{figure}

\textbf{Data Capture and Processing}. We first retrieved workflow metadata from a biological repository (content of the ArrayExpress\footnote{\url{http://www.ebi.ac.uk/arrayexpress/}} archive), through use of a multi-threaded harvesting operation.
All experimental workflows were then converted using a MAGE-Tab \cite{rayner2006simple} to ISA-Tab \cite{rocca-serra10,sansone12} converter, the latter format being more general than the former and can be used to carry metadata payloads for many types of experiments, making the data processing program more ``future-proof'.

From the 21,000 ISA-Tab files, we extracted all names of protocols (processes) and biological materials, chemical materials, devices and data used in annotation. We also computed the occurrence of each material and process found in the entire set of ISA-Tab files, which have been used as one of the metrics in the next stage (see Section 5 for details). This step results in 61 process names and 3,492 names of inputs and outputs (e.g., biological and chemical materials, device measurements and data).

\textbf{Taxonomy Formulation}. Since a taxonomy for such a large collection of terms is absent, we, for starters, established a set of categorisation schemes with the help of domain experts. For example, one of the schemes for categorising processes may be based on different biological inputs to a process (\eg, molecule, cell, or organism). Another scheme may be based on processing methods (\eg, perturbation, combination). We computed the quality measures of each scheme based a set of generic metrics (see Section \ref{sec:Taxonomy}) then created a taxonomic tree by recursively selecting the best categorisation scheme based on the quality measures. We finalised the organisation of the taxonomy by allowing domain experts to make adjustments according to domain-specific conventions. All leaf nodes of the resulting taxonomy tree are names extracted from the workflow metadata. All non-leaf nodes represent a categorisation scheme.

\textbf{Glyph Design}. First, we established an ordering of commonly-used visual channels based on the literature focused on perception and visualization (see Section \ref{sec:Glyphs}). This allows us to systematically compare the order of categorisation schemes in the taxonomy with the order of different visual channels. Ideally, schemes at the upper level of the tree can be mapped to visual channels which are more prominent to our visual system.

We then proceeded to the glyph design process involving two intertwined sub-processes for \textbf{visual mapping} and \textbf{metaphoric abstraction and association}.
Various options of visual channels for each categorisation scheme featured in the taxonomic tree.
Next we considered the merits of these visual channels and identify potential conflicts with the visual channels that have been assigned to other schemes.
With direct help from domain experts, we tried to identify a metaphoric abstraction or association for each design option proposed.
We evaluated and recorded the intuitiveness and suitability of the abstraction and metaphor association.

Informed by the results the two sub-processes, we finalised a glyph set by selecting a design option for each scheme, while maintaining the order of discriminative capacity of visual channels, minimising conflicts between different channels, and maximising the use of metaphoric abstraction and association.

\textbf{Implementation of Glyph-based Visualization}.
We then integrated the glyph set with a layout algorithm to form a prototype system for workflow visualization (see Section \ref{sec:Workflow}).
For demonstration purposes, we tested the workflow visualization in conjunction with ISAcreator \cite{rocca-serra10}, a popular domain agnostic biological experiment metadata capture tool.

% ==================
\section{Taxonomy Generation}
\label{sec:Taxonomy}

Given a large collection of concepts, we should ideally make use of a standard taxonomy, where non-leaf nodes represent different categorisation schemes and each scheme provides subclasses that lead to different sub-trees. In many circumstances, however, there is no agreed taxonomic tree as establishing a standard categorisation requires non-trivial scientific effort that often spans over a few decades.

The algorithm described below is not intended to establish a semantic-rich taxonomic tree for classifying concepts.
It is designed purely for addressing the needs for ordering various categorisation schemes (when there is no agreed order) to aid glyph design, and for devising a useful tree data structure in implementing the mapping between concepts and glyphs in workflow visualization.

Hence, the criteria used for structuring the tree are based on usage of the concepts and the structural quality of the tree to be constructed.

Taxonomy is a long standing concept that can be traced back to 3000BC \cite{maguire12}. Automatic taxonomy generation has been an active field in computer science and computational biology with existing work largely focusing on clustering algorithms (e.g., \cite{krishnapuram03}). Many such algorithms assume the availability of similarity measures for ordering entities rather than relying on the existence of individual categorisation schemes. In these algorithms, there is usually no attempt towards application of a metric for creating meaningful non-leaf nodes in the resulting tree. In this work, it is essential to keep each categorisation scheme as a non-leaf node unless it is redundant.

\subsection{Ordering Classification Schemes}
\label{sec:Algorithm}

Let $\mathcal{X} = \{ x_{1}, x_{2}, \ldots, x_{n} \}$ be a set of concepts to be classified.
In our application, this is the set of all valid names of biological processes and IOs (inputs and outputs) in the database.
Each concept $x_i$ is associated with a scalar value, $\mu_i \in [0, 1]$, indicating its frequency of usage in relation to the total occurrence of all concepts in the database.
There are a number of categorisation schemes, $\mathcal{S} = \{ S_1, S_2, \ldots, S_m \}$.
Each scheme, $S_k$ divides concepts into several classes, $c^k_1, c^k_2, \ldots, c^k_{l_k}$.
The relationship between the concept set $\mathcal{X}$ and different classification schemes can thus be represented by a Boolean matrix, $\mathbf{A}$, where each element $\alpha[i,j,k] = 1$ if concept $x_i$ belongs to the $j^{th}$ class of scheme $S_k$; otherwise $\alpha[i,j,k] = 0$.
In the context of feature-based categorisation, one can also view each scheme $S_k$ as a feature, and each class under $S_k$ as a particular type of this feature.
Without losing generality, we assume that the classes under the same $S_k$ are disjoint.
It is also possible that a concept does not possess the $k^{th}$ feature, and hence does not belong to any class under $S_k$.

Given the above categorical information about the concept set $\mathcal{X}$, one can choose a categorisation scheme $S_k \in \mathcal{S}$, which will divide $\mathcal{X}$ into a number of disjoint subsets corresponding to classes $c^k_1, c^k_2, \ldots, c^k_{l_k}$ and $c^k_0$.
The subset $c^k_0$ contains those concepts which $S_k$ is unable to classify.
The partitioning process can be repeated recursively by applying one of the remaining categorisation schemes in $\mathcal{S}$ to each subset.
This results in a hierarchical categorisation tree, which defines a taxonomy for the concepts set $\mathcal{X}$.

The ordering of the schemes in $\mathcal{S}$ thus determines the taxonomic structure of $\mathcal{X}$.
It is not difficult to anticipate that many criteria can be used to determine the ordering for a given concept set.
Some criteria will no doubt encode application-specific semantics, and some may be subjective or debatable.
However, there are also some common-sense criteria that are generic to most applications.
These include:

\textbf{Coverage}.
The number of concepts that can be classified by scheme $S_k$ is a capacity measure of $S_k$.
The more concepts that $S_k$ can classify (the fewer in $c^k_0$), the better.
The measure, which is normalised by the set size $\mid\!\mathcal{X}\!\!\mid=n$, can be defined as:

\begin{equation}
\label{eq:Coverage}
  M_1(S_k) = \frac{\sum_{i=1}^{n} \max_{1 \leq j \leq l_k} (\alpha_{i,j,k})}{n}.
\end {equation}

\textbf{Potential Usage}.
A categorisation scheme that is higher up in the taxonomical tree is expected to be used more often in the application concerned.
The occurrence frequencies of concepts, $\mu_i$, enable us to estimate the potential usage of a classification scheme as follows:

\begin{equation}
\label{eq:Usage}
  M_2(S_k) = \frac{\sum_{i=1}^n \mu_i \max_{1 \leq j \leq l_k} (\alpha[i,j,k]) }
  {\sum_{i=1}^n \mu_i}.
\end {equation}

\textbf{Subtree Balance}.
Having a balanced node distribution in a tree is a desirable property of a tree structure.
It prevents a tree from having an excessive height, which corresponds to the need for more visual channels.
Let $l_k$ denote the number of subclasses in categorisation scheme $S_k$, $\tau_j$ be the number of concepts in each subclass $c^k_j, j=1, 2, \ldots, l_k$, and $\sigma_{\tau}$ and $\bar\tau$ be the standard deviation and mean of $\tau_1, \ldots, \tau_{l_k}$ respectively.
We can measure the level of balance as follows:

\begin{equation}
\label{eq:Branch}
  M_3(S_k) = \begin{cases}
    0 & \sum_{i=1}^{l_{k}} \tau_{l_i} = 0 \\
    1 & \sigma_{\tau} < \epsilon (\epsilon \gt 0) \\
    P(\bar\tau \pm1 \mid N_{\bar\tau, \sigma_{\tau}}) & \bar\tau \gt 0 \; \& \;\sigma_{\tau} > \epsilon
  \end{cases}
\end {equation}

\noindent where $P$ is the probability that a value within $[\bar{\tau}-1, \bar{\tau}+1]$ falls under
the curve given by the normal distribution $N$ with $(\bar{\tau}, \sigma_\tau)$ \cite{patel96}.
There are two special cases.
When all values of $\tau_j$ are 0, $S_k$ cannot classify any concept; hence the metric returns a zero score.
When $\sigma_\tau = 0$, the subtree is totally balanced; hence the metric returns one.
As $\sigma_\tau$ approaches zero, the function $P$ becomes numerically unstable, we use a cut-off value $\epsilon$ to prevent this. In this work, we set $\epsilon = 0.00001$.
The normal distribution is preferred over a $\chi$-test, as $\chi$ may not be reliable when $l_k$ is a small number.

\textbf{Number of Subclasses}.
All visual channels used in glyphs have limited discriminative capacity.
A higher number of subclasses in a scheme would require visual encoding to have more codewords (\eg, more colours or more shape types), which will increase users' cognitive load in learning, remembering, and recognising the codewords.
It is thus more desirable to have a smaller number of subclasses, except that a categorisation scheme with fewer than 2 sub-classes is useless.
Let $\eta^{\top}$ be an upper limit for the number of codewords, which is set to 10 in this work.
We introduce the following metric to measure the discriminative capacity of a scheme:

\begin{equation}
\label{eq:Branch}
  M_4(S_k) = \begin{cases}
    0 & \eta_k < 2 \\
    \frac{\eta^{\top}-\eta_k+2}{\eta^{\top}} & 2 \leq \eta_k \leq \eta^{\top} \\
    \frac{1}{\eta^{\top}} & \eta_k > \eta^{\top}
  \end{cases}
\end {equation}

Although the above four metrics have been normalised to ensure their functional values within the $[0, 1]$ domain, the distribution of the values for different schemes can still be rather application-specific and may vary substantially between different metrics. This may lead to inconsistency in combining these metrics.

Therefore we provide an optional linearisation filter for these metrics by mapping the values obtained using each metric $M_i$ into fractional ranking numbers.
These are then normalised into the $[0, 1]$ domain with 1 being the best and 0 the worst.
For example, consider a set of six schemes with metric values:
\[
  (S_1, 0.5), (S_2, 0.3), (S_3, 0.54), (S_4, 0.8), (S_5, 0.85), (S_6, 0.6).
\]

\noindent We first sort the set:
\[
 (S_2, 0.3), (S_1, 0.5), (S_3, 0.54), (S_6, 0.6), (S_4, 0.8), (S_5, 0.85)
\]

\noindent We then obtain the normalised ranking values via the \emph{distance for ordinal variables} function $\sigma=\frac{r-1}{R-1}$ where $R$ is the top rank and $r$ is the rank position for each schema.
\[
  (S_2, 0), (S_1, \frac{1}{5}), (S_3, \frac{2}{5}), (S_6, \frac{3}{5}), (S_4, \frac{4}{5}), (S_5, \frac{5}{5}).
\]

We denote this filter as a function $R(S_k, M_i, \mathcal{S})$. Using the above set of metrics in conjunction with the filter $R$, we can derive a combined metric as
\[
  M(S_k) = \frac{\sum_1^4 \omega_t R(S_k, M_t(S_k), \mathcal{S})}{\sum_1^4 \omega_t}.
\]

\noindent where $\omega_t, t=1,2,3,4$ are user-adjustable weights for the four individual metrics. Similar to weights in clustering algorithms, these weights need to be used with care as they introduce additional semantics into the ordering algorithm. 

Equipped with the combined metric $M$, the algorithm for establishing an order of different schemes in $\mathcal{S}$ can be described as follows:

\begin{algorithm}
\caption{Scheme selection algorithm}
 \begin{algorithmic}[1]
 	\Function {select}{$\mathcal{S}$, $\mathcal{X}$} 
 		\State $S_{BEST} \gets null$  
		\State $m_{BEST} \gets 0$
		 \ForAll {$S \in \mathcal{S}$}
       			\State $m \gets M(S)$;
	       		\If{$m > m_{BEST}$}
           			\State $S_{BEST} \gets S$; 
					\State $m_{BEST} \gets m$;
            		\State output($S_{BEST}$);
           			\State remove $S_{BEST}$ from $\mathcal{S}$
            		\State split $\mathcal{X}$ into subsets $\mathcal{X}_{1}$, $\mathcal{X}_{2}$, $\ldots$, based on $S_{BEST}$

           			\If{$\mid subsets \mid \leq 1$}
                 				\Return 
         				 \EndIf
         			 
				\For{each subset $\mathcal{X}_{k}$}
              		\State \Call{select}{$\mathcal{S}, \mathcal{X}_{i}$}
         		\EndFor
     			\EndIf
  		\EndFor 
	\EndFunction
\end{algorithmic}
\end{algorithm}

% To illustrate our approach more clearly we present a more simple example related to classification of household items.

\subsection{Application to the Biological Case Study}
%
The biological community has built over the years a comprehensive collection of resources to archive experimental data. As molecular biology became a more data intensive field with the advent of DNA microarrays, came the need to store not only measurements but also ancillary annotation describing experimental conditions and set up, thus ensuring a metadata core always shipped with the data set. The size of microarray databases such as GEO \cite{barrett2011ncbi} and ArrayExpress \cite{ArrayExpress::2012} constitute prime resources for evaluating and testing our approach.
The content of ArrayExpress was therefore accessed obtaining data via parallel calls, converting 21,000 experiments and associated experimental metadata to ISA-Tab\cite{rocca-serra10,sansone12}.
This step provided a harmonised format in which to represent not just transcriptomic data, but also genomic, proteomic, metabolomic, and other classical experiment types.

Given the data sets, the code analyses the content of these directories to determine the processes and IOs which exist within the experiments, and the number of times they occur. The analysis revealed 61 processes (a small number resulting from the homogeneity of the database where analysis techniques are targeted primarily towards DNA microarrays) with 1,845,089 occurrences and 8,223 properties of the sample of which 3,492 were deemed to be IOs with 486,353 occurrences.

Several distinct, empirical but meaningful, categorisations were devised encompassing a number of facets defining the properties of the experimental process, either in terms of its participants or in terms of key process properties. Classifications, based on features such as the nature of process participants, the granularity scale, the nature of experiments and common types a treatments applied in biological experiments were developed. Some classifications were somewhat informed by the overall assumptions ISA model relies upon, where nodes can be either material or data files and where edges are processes acting upon those nodes. Others resulted from applying a small number of axioms discovered through consultations with domain experts. There were 6 classification schemes in all with a total of 23 sub-classifications, these are detailed in Figure \ref{fig:fitness-classification}.
Table \ref{table:input-fragment} shows a snapshot of the input file used in the classification algorithm.

\begin{table}[t]
\begin{center}
\vspace{1mm}
\scalebox{0.88}{

\begin{tabular}{l|ccc|c|ccc}
\hline
\textbf{Process Name} & \textbf{Occurrences} & \textbf{S1:Material} & \textbf{S1:Data} & \textbf{\ldots} & \textbf{S6:in vitro} & \textbf{S6:in vivo} & \textbf{S6:in silico}\\
\hline
\textit{labeling} & 390811 & 1 &  & \ldots & 1 &  &  \\
\textit{nucleic acid extr.} & 350267 & 1 &  & \ldots & 1 &  & \\
\textit{hybridization} & 345671 & 1 &  & \ldots & 1 &  &  \\
\textit{feature extr.} & 267044 &  & 1 & \ldots &  &  & 1 \\
\textit{bioassay data trans.} & 176347 &  & 1 & \ldots &  &  & 1 \\
\textit{grow} & 116194 & 1 &  & \ldots &  & 1 &  \\
\textit{pool} & 68004 & 1 &  & \ldots & 1 &  &  \\
\ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots & \ldots \\
\hline
\end{tabular}
}
\end{center}
\caption{A fragment of the input document passed to the taxonomy generation algorithm. Schemes are grouped by common names preceding the semi-colon, \eg, \emph{S1:On Material} refers to schema 1 and \emph{On Material} is the classification.}
\label{table:input-fragment}
\vspace{-5mm}
\end{table}

The schemes are not tied to any existing taxonomic tree, may not be orthogonal and/or may be redundant with respect to others.
The development of the classifications was not the result of application of any knowledge engineering methods and there is no ontological commitment, although in theory the classification names used could be derived from an ontological framework.
The reason for not relying an ontology in the first place was risk mitigation.
Use of an ontology would have almost certainly resulted in an unbalanced tree since occurrence counts for the terms would not be considered.
This would have resulted in the creation of many glyphs that would never be used. 

\begin{figure}[ht!]
\centering
\includegraphics[width=\textwidth]{images/glyph-taxonomy/fitness-classification}
\caption{The classification algorithm arranged the classification schemes in the above order where \emph{S} indicates a \emph{scheme}, and \emph{C} represents a category within each scheme.}
\label{fig:fitness-classification}
\vspace{-10pt}
\end{figure}

The creation of the tree shown in Figure \ref{fig:fitness-classification} was a largely iterative quest with continuous involvement of domain experts checking to ensure that the classifications assigned were meaningful. From early versions of the classification matrix creation, classifications were removed, added or merged in consultation with those who knew the data domain. For example, in \emph{S2} there were sub-classifications in \emph{Genetic Modification \& Labeling} which are types of \emph{Material Combination}. Therefore, these sub-classifications were removed since it would be technically and semantically incorrect to keep them. These early interactions emphasised the importance of having domain experts in the loop, otherwise classifications and subsequent glyphs would not be as well created as they could be.

The algorithm managed to correctly place the classifications where they were expected (checks were made by hand to ensure that the algorithm performed well).
Schema \emph{S6} (\emph{in vitro}, \emph{in silico}, and \emph{in vivo}) was the best top level classification due to its overall fitness metric of 3.08 with individual metrics found to be: M1 = 1.0; M2 = 1.0; M3 = 0.9; and M4 = 0.18.
\emph{S6} was closely followed by \emph{S1} (on material and on data), however after the top level separation, \emph{S1} became redundant as a result of the top level implicitly making a split on data (in silico) and materials (in vitro and in vivo). The algorithm successfully detected this redundancy; hence $S1$ is absent from Figure \ref{fig:fitness-classification}. 

Although the algorithm performed as expected, a possible criticism of the algorithm could be highlighted in the placement of \emph{S5} below \emph{S4}.
\emph{S5} could have been placed above \emph{S4} in line with the observation that, for the majority of cases, \emph{S5} was selected over \emph{S4}.
The reason \emph{S5} was not used to sub-classify C1 of \emph{S4} is due to its number of classifications (7) being greater than that of \emph{S4} (3), therefore \emph{S4} was selected primarily on this metric even though the sub-tree balance of \emph{S5} (0.8) was slightly better than that of \emph{S4} (0.68).
To modify this behaviour, it was necessary to involve domain experts in refining the tree based on their domain-specific knowledge and case-specific requirements.

% ---------------------------------------
\input{tables/glyph-taxonomy/table-visual-variables}
%\input{tables/glyph-taxonomy/table-visual-variable-comparison}

% ==============
\section{Visual Encoding}
\label{sec:Glyphs}

This section describes how we move from the items in the taxonomy to their glyph representations. First, we bring attention to a number of principles and design guidelines taken from Chapters \ref{chap:related_work} and \ref{chap:strategies}.
Using these guidelines, we then show how glyphs can be created by using the taxonomic organisation created in the previous step.

\subsection{Perceptual Guidance}
%
%\emph{glyph} is a small visual object composed of a number of \emph{visual channels} which can be used independently as well as constructively to depict attributes of a data record.
Glyphs, as discussed in Chapter \ref{chap:related_work}, are a type of visual sign that may make use of visual features of other types of signs, such as icons, indices, and symbols.

Although there are several books on sign design such as those by Barker and Fraser \cite{barker00} and Abdullah and H\"{u}mber \cite{abdullah06}, they focus on signage in public space, and offer empirical guidance on a large number of issues including standardisation, size, location, illumination, and so on.
Many of these issues are not quite relevant to the need for visualising the workflows of biological experiments.
Here, we draw our design principles mainly from findings in perception by Spoehr and Lehmkuhle \cite{spoehr82} and Quinlan \cite{quinlan03}, especially in the area of visual search.

While the extensive use of signs, icons, and pictograms in everyday life reflects their usefulness and effectiveness, several perceptual studies also directly or indirectly confirmed their perceptual and cognitive merits.
For example, Franks and Bransford's study on transformation of prototypes \cite{franks71} suggested that humans can learn to recognise glyphs by rules consciously as well as unconsciously.
Sperling \cite{sperling60} suggested the presence of iconic memory that may facilitate rapid comparison between glyphs in the same display, whereas the effect is less so for text.

\textbf{Guideline on Semantic Relevance}.

Chapter \ref{chap:related_work} Section \ref{sec:retinal_variables} presented the body of research around the visual channels and categories (\emph{associative}, \emph{selective}, \emph{ordered} and \emph{quantitative}) as initially defined by Bertin \cite{Bertin:1983:book}, their power as defined by Stevens \cite{stevens1975}, and their suitability to particular data types as defined by Cleveland \cite{cleveland1984graphical}, Mackinlay \cite{mackinlay1986automating}, Heer and Bostock \cite{heer2010crowdsourcing}, and Ware \cite{ware2010visual}.

Using Bertin's criteria, visual channels can be organised by their suitability to particular types of data.
This means that colour hue for example is not used to map \emph{quantitative} or \emph{ordered} data, but should be used to map \emph{associative} or \emph{selective} data.  

This guideline helps in the glyph design process through enforcing appropriate visual mappings from a data type.

\textbf{Guideline on Channel Composition}.
As a glyph is likely to feature a number of visual channels, the constructive composition may affect how individual channels are perceived.

As discussed in Chapter \ref{chap:related_work} Section \ref{sec:channel-composition}, the theory of integral and separable dimensions is important in glyph design.
Through choosing an integral set of dimensions to represent data in a glyph, it is likely that users will be unable to distinguish between glyphs with similar characteristics on at least one of the dimensions chosen. 

This guideline, serves to inform designers of the difficulties that may appear when using particular combinations of visual channels, which are the worst (\eg, width and height), and which are best (\eg, colour and position).

\textbf{Guideline on Pre-attentive Processing}.
Described in detail in Chapter \ref{chap:related_work} Section \ref{sec:popout}, many classic studies in perception established the ``power'' of different visual channels in terms of their ability to \emph{pop-out} pre-attentively.

This guideline can inform designers of the strength of a visual channel.
This effect, in combination with where the visual channel is positioned in the glyph (visual hierarchy) can be used to bring attention to the most important objects in the display. 


\textbf{Guideline on Visual Hierarchy}.
%
\emph{Visual hierarchy}, with which the environment and objects around us are arranged is a well documented theoretical framework discussed in Chapter \ref{chap:related_work} Section \ref{sec:global_local_processing}.
Because glyphs are relatively small in comparison with the whole visualization, we consider them to be at the ``local level'' of the visualization, that is, the whole shape of the workflow will be the global feature of the visualization with the local components being the individual glyphs. 
At this overview level, not all features of a glyph may be perceivable.
The overall colour of the glyph will be seen for example, but not all of its components.
On finding an area of interest at the overview (\eg particular sequence of coloured nodes), a user may zoom in to an area of the workflow where glyphs can be perceived more easily. 
Even so, at this point, each glyph will have it's own global and local space. 
The overall shape or colour of the glyph will occupy a global space and will be perceived at lower resolutions than small features that occupy a local space that require higher resolutions to be perceived correctly.
Zooming in more will make the features requiring high spatial frequencies visible.

This guideline serves to inform the design process through prioritising the position in a glyph some variable occupies depending on its importance.
Important data should be mapped to visual channels that occupy a level within the glyph that makes it more visible and therefore selectable by users. 
Data that is less important to user tasks should use visual channels and areas of the glyph that are more perceivable at the zoomed in level.


\begin{figure}[t]
\centering
\includegraphics[width=.7\textwidth]{images/glyph-taxonomy/glyph-space.eps}
\caption{A) The glyph template with a main body, an interior region and an exterior region (consisting of 4 sections).
B) Our final design makes use of the main body and interior region.
The exterior is reserved for future extension.
% As we proceed to lower levels, size will have an impact on visual power\cite{duncan89}.
}
\label{fig:glyph-design}
\vspace{-10pt}
\end{figure}

Based on this perceptual guidance, we considered a generic glyph design template as shown in Figure \ref{fig:glyph-design}(a).
The template divides a glyph into three regions, namely \emph{main body}, \emph{exterior}, and \emph{interior}.
In practice, each region can be divided into two or more sub-regions (\eg, a twin body glyph or four exterior sections), it is convenient to consider the three regions in abstraction.
The separation of these regions facilitates the basic separation of visual channels based on the composition guideline, while allowing us to consider them individually according to the hierarchy guideline.

In theory, the exterior and interior regions may also be divided into sub-regions in a recursive fashion though in practice this is tightly constrained or discouraged by the very limited display resolution typically available for glyphs.
Similar to the design convention for icons, pictograms are normally featured in the interior region.
The exterior region may be further divided in four sections (top, bottom, left, and right).
If glyphs will be connected to form a network or graph (as is the case in this work), the use of these four sections has to take into account the possible incoming and outgoing connections.

Table \ref{tab:visual-variables} summarises relative merits of some of the most commonly-used visual channels in different regions according to Bertin's categorisation, pop-out effects and hierarchy effects.
We estimated the overall discriminating capacity of each channel by using a summary rating in the penultimate column.
We also recognised the importance of the conventions and metaphors in an application.
We will discuss visual metaphors further in Section \ref{sec:Mapping}.
We added the last column to highlight the necessity to consider these in a design process.

It is difficult to establish an accurate ranking order of different visual channels by taking all perceptual effects into account in a quantitative manner.
The state of the art in perception research is yet to provide all evidence needed for a full and conclusive analysis.
Nevertheless, Table \ref{tab:visual-variables} can serve a qualitative guidance to glyph designs in this work, providing an ordering of visual channels in parallel with the ordering of categorisation schemes discussed in Section \ref{sec:Taxonomy}.

% ---------------------------------------------------------
\subsection{Mapping the Taxonomy to Visual Channels}
\label{sec:Mapping}

For each scheme in the taxonomic tree as shown in Figure \ref{fig:fitness-classification}, we propose a number of design options.
Figure \ref{fig:glyph-design-options} shows some examples of the proposed designs.
For example, the first column shows the use of colours to encode the classes of a categorisation scheme.
The second column shows the use abstract shapes.
Some options convey an abstraction from pictorial representations of classes, and in other cases, we try to establish a metaphoric association between a visual channel and a biological categorisation.

Metaphoric visual representations enable domain-specific encoding using ``natural mappings'' \cite{siirtola05,norman02}.
McDougall \etal stated that natural mappings can make it easier for users to infer meaning from the glyph with less effort required to learn and remember them \cite{McDougall00}.
A recent study by Borgo \etal showed that visual metaphors can aid memorisation of the information depicted in a visualization \cite{Borgo12}.
However, the same study also showed that visually realistic metaphors 
(those with a lot of detail) may have a negative impact on performance in visual search.
Moreover, realistic visual metaphors require a higher pixel resolution, and would lose their discriminating capacity in low resolution conditions. 

\begin{figure}[t!]
\centering
\includegraphics[width=.65\textwidth]{images/glyph-taxonomy/design-options.pdf}
\caption{Experimenting with visual channels: an overview of the various design options available for use in representing the process branch of the taxonomic tree.}
\label{fig:glyph-design-options}
\vspace{-10pt}
\end{figure}

Based on the design options shown in Figure \ref{fig:glyph-design-options}, we followed the taxonomic tree in Figure \ref{fig:fitness-classification} and identified the best option for each scheme in a hierarchical manner.
The evaluation criteria include:
%
\begin{itemize}
\item
the discriminating capacities of different channels (Table \ref{tab:visual-variables});
\item
metaphoric capacity for aiding learning and remembering;
\item
potential conflicts, including spatial, perceptual, and metaphoric conflicts, with visual channels that have already been assigned to other schemes in the tree;
\item
encoding costs in terms of requirement for pixel resolution.
\end{itemize}

This process normally takes a few iterations, during which new design options and new metaphoric abstractions/associations may be proposed.

\begin{figure}[t!]
\centering
\includegraphics[width=.6\textwidth]{images/glyph-taxonomy/glyph-design-selection.eps}
\caption{Formation of the final glyph design. Top level items require the greatest visual power.
It is important to be able to distinguish each of the processes based on their parent level in the taxonomy.
Distinguishable global shapes provide the difference between IOs (circles) and processes (squares with pointed bottom to indicate directionality).}
\label{fig:glyph-design-selection}
\vspace{-10pt}
\end{figure}

Based on the hierarchy in Figure \ref{fig:fitness-classification}, we considered to use colour and shape options for S0 (IOs \emph{vs.} processes) and S7 (four classes of IOs).
As introducing four main body shapes to encode IOs is not an effective mapping for learning and remembering, we decided to assign outline colour of the main body to encode S7, and use two basic shapes, circle and pentagon (a rectangle with a pointer to show workflow direction) to encode S0.
Since the main body or the pentagon will only be coloured in black or white, S0 also implicitly encoded in using colour symbolism, that is, colour for IOs and black/white for processes.
In effect, S0 is encoded using two visual channels.
As stated by Chen and J\"{a}nicke, this redundancy can help in error detection for visualization \cite{Chen10}.

Figure \ref{fig:glyph-design-selection} shows each of the five schemes for the process subtree, and the design option chosen from Figure \ref{fig:glyph-design-options}.
Below we discuss our reasoning for selecting each of the design options for each scheme in the taxonomy.


\textbf{S6: Process environment}.
The taxonomic tree suggested a high priority for visual mapping, which is consistent with the domain experts' intuition.
We took advantage that black colour was not used by S7 for IOs, we assigned a white background to \emph{in silico/in computer} (related to computational processes), and black to \emph{in vivo/in living} and \emph{in vitro/in glass} (related to materials).
Further more, we made use of a shape-based metaphor, fully-filled background for \emph{in vivo} (whole organism), and black background with white cut out for \emph{in vitro} (component of an organism).
Together, this was given in Figure \ref{fig:glyph-design-options} as design option 6.
We maintained the overall appearance of the main body of process glyphs in black and white to avoid potential clash with material glyphs.

\textbf{S2: Types of Material Manipulation}.
S2 has five classes, and we adopted design option 7, which employs visual metaphors that encapsulate strong domain-specific meanings.
For example, visual symbol for the \emph{material amplification} class depicts a small segment becoming a large segment.

\textbf{S4: Type of Experimental Perturbation}.
S4 defines three further sub-classes of the \emph{material perturbation} class of S2.
Due to the low number of subclasses, we made use of line styles to modify the diamond shape of the \emph{material perturbation}.
We made metaphoric association of three line styles as:
``solid'' line for physically induced perturbation;
dash line, a common metaphor for uncertainty and unpredictability, for behaviourally induced perturbation; and
wavy line, which is closer to a circle (a visual signature for IOs), for material induced perturbation.

\textbf{S5: Levels of Material Granularity}.
This scheme has seven subclasses (molecule, cellular part, cell, tissue, organ, organism, and population), and finding a suitable visual channel was not straightforward.
A more simple approach would be to use colours to fill the interior of the glyph, or to use some shape-based encoding.
After consulting the domain experts, these two options were ruled out.
In fact, domain experts preferred some pictograms to represent the seven subclasses.
After considering a number of more realistic drawings, we found that it was not easy to create realistic representations that can differentiate all subclasses (\eg, cellular part \emph{vs.} cell, and organ \emph{vs.} organism).
We designed a special set of icons as shown in Figure \ref{fig:s5-metaphor} with three visual channels to aid learning, memorisation, and recognition.
The first visual channel is the overall shape and orientation.
The second visual channel is metaphoric abstraction and association.
For example, the shape of cell part indicates a portion of a cell.
Tissue is associated with a patch, organ with an abstract heart shape, organism with an abstract human, population with two abstract humans.
The third visual channel is the number of orange sub-shapes, representing the levels one to seven.
\begin{figure}[t!]
\centering
\includegraphics[width=.8\textwidth]{images/glyph-taxonomy/s5-metaphor.eps}
\caption{Visual representations of the seven classes in \emph{S5}.}
\label{fig:s5-metaphor}
\vspace{-10pt}
\end{figure}

\textbf{S3: Types of Data Manipulation}.
S3 defines three further sub-classes of the \emph{in silico} class of S6.
We use three abstract pictograms to represent data capture, processing, and analysis.
The encoding makes use of the difference in overall shape, orientation, and number of triangles to aid learning, memorisation, and recognition.
Note that these shapes will not be confused with those for S5 as the white background of the main body provides a distinct context of computing rather than IOs.

\begin{figure*}[t!]
\centering
\includegraphics[width=\textwidth]{images/glyph-taxonomy/full-tree.eps}
\caption{Overview of the taxonomy based glyph designs in the context of biodomain.}
\label{fig:full-tree}
\vspace{-5pt}
\end{figure*}

Following mapping of all schemes to design options, creation of all glyphs is a straightforward process.
Figure \ref{fig:full-tree} shows all variations of the glyphs associated with the process sub-tree.

We introduced a ``crush'' test for the designed glyphs by scaling it to different pixel resolutions.
Figure \ref{fig:crash-test} shows some example glyphs displayed at varying resolutions.
One can comfortably see all details at the 40$\times$40 level.
At the 10$\times$10 level, one can observe the visual signature of \emph{in vivo} and \emph{in vitro}.
Even at the lowest level (5$\times$5), one can still differentiate the two glyphs. 

\begin{figure}[t!]
\centering
\includegraphics[scale=1]{images/glyph-taxonomy/crash-test.eps}
\caption{A ``crush'' test of glyphs to evaluate the discriminating capacity of various visual channels at different resolutions.}
\label{fig:crash-test}
\vspace{-5pt}
\end{figure}

% ===============
\section{Workflow Visualization and ISA Integration}
\label{sec:Workflow}

In order to visualise workflows of biological experiments, we had to address the following technical issues:
1) mapping from a name in the metadata to a glyph;
2) creating a workflow visualization with both node placement and connection display;
3) developing a prototype tool for a practical environment such as the ISA tools framework\footnote{\url{http://www.isa-tools.org}}.

The mapping from concept name is achieved by a look-up table which is built from the matrix used in formulating the taxonomic tree and implemented as a tab delimited file.
Each concept name is mapped to a text tag encoding the traversal path from the root of the tree to the leaf node corresponding to the name.
The tag includes identifiers of the schemes and classes encountered.
With the path, a glyph can be constructed dynamically from the pre-defined visual mapping as described in the previous section.
The look-up table also enables storage of pre-rendered glyphs in an image format.

To generate the workflow, we made use of the layout algorithm available within the Prefuse visualization framework created by Heer \etal \cite{heer05}.
This framework also brings with it functionality such as panning, zooming, and filtering which bring more interactivity to the user and making navigation through large collections of workflows easier. 
The only requirement for use of Prefuse was a minimal amount of Java code to create the user interface coupled with creation of an XML file format native to Prefuse for representation of the tree structure.
This XML format is configurable, we have configured it to contain: \emph{node type} (\eg, process), \emph{node name} (\eg, labelling), and an image to be rendered, which is assigned using a look-up operation through the above mentioned tab delimited mapping file. 
The order of the XML elements within this file has direct implications on the order these elements are displayed in. 
Within the ISA-Tab format, there is an implicit time element found in the ordering of the columns in the study sample and assay files. 
This can be used to construct the XML elements through near direct mappings of processes and Input/Outputs, a workflow which is illustrated in Figure \ref{fig:generating-workflow-from-text}. 
Recognising branching events is an important part of workflow visualization as illustrated in \ref{fig:generating-workflow-from-text}. 
In software, these branch events can be identified when the preceding nodes of a process have the same names while the succeeding output nodes are different. 
Figure \ref{fig:generating-workflow-from-text} highlights one such case, where branching occurs after extraction of three materials from one sample. 

Our software reads text-based ISA-Tab files as illustrated to create the XML notations required by Prefuse for rendering the experiment workflow illustrated in Figure \ref{fig:teaser} B).

\begin{figure}[t!]
\centering
\includegraphics[width=\textwidth]{images/glyph-taxonomy/generating-workflow-from-text.eps}
\caption{A workflow is recorded in text form within the ISA-Tab format.
Our software translates it to a glyph-based visualization.
A branching event is automatically detected during the translation.}
\label{fig:generating-workflow-from-text}
\end{figure}

\begin{figure}[ht!]
\centering
\includegraphics[width=\textwidth]{images/glyph-taxonomy/bio-workflow-example.eps}
\caption{A user can interact with a workflow to view the text descriptions of individual glyphs in pop-up windows, which are also dynamic legends showing how the concept is categorized and how the corresponding glyph is decomposed into different elementary visual representations. 
Users can also use such a legend to find out other classes in a categorization scheme.}
\label{fig:bioworkflow-example}
\end{figure}

The software is implemented as a Java application capable of processing ISA-Tab files to create experimental workflows using glyphs. 
For the purposes of broad dissemination in the near future, we have integrated the workflow visualization directly inside ISAcreator, a Java desktop application for creating and editing ISA-Tab files. 
Furthermore, the standalone workflow visualization shown in Figure \ref{fig:bioworkflow-example} makes use of the same ISA-Tab parser available within ISAcreator. 
The integration involved the development of user interface elements for ISAcreator software to access the workflow visualization.

Although it was established by Franks and Bransford \cite{franks71} that people can learn rules of glyph encoding consciously as well as unconsciously, we do not expect users to learn and remember these glyphs without help. 
We therefore allow users to find detailed text descriptions in pop-up windows interactively. 
As shown in Figure \ref{fig:bioworkflow-example}, not only do these windows provide names of processes and Input/Outputs, they also serve as dynamic legends, showing how each glyph is decomposed into different elements corresponding to categorisation schemes. 
One can also select a component to view all classes in a scheme.   

\section{Contributions}
\label{sec:glyph_tax_contributions}

In this chapter, we have presented a systematic approach for glyph design by using taxonomy as a guide. 
The approach was demonstrated by computationally analysing the content of a biological database using our novel tree-building algorithm, generate a taxonomic tree by optimally arranging a set of categorisation schemes.
This enabled us to draw a parallel between the ordering of categorisation schemes in the taxonomic tree with the ordering of visual channels compiled from the perception and visualization literature from Chapter \ref{chap:related_work}.
We involved two domain experts, both biologists from the University of Oxford (Dr. Susanna-Assunta Sansone and Dr. Philippe Rocca-Serra) in refining the tree as well as in creating metaphoric abstraction and association for glyphs.

This work was published in IEEE TVCG in a publication by Maguire \etal \cite{Maguire:2012:TVCG} and presented in the InfoVis track at IEEE VIS 2012.

In the next chapter, the work presented in this chapter is extended to create ``macro'' glyphs for the visual compression of workflow graphs.
